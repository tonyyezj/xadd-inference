Boyan and Littman~\cite{boyan01} presented the first exact solution
for 1D continuous HMDPs with discrete actions, linear reward and
piecewise dynamics while Feng {\it et al}~\cite{feng04} generalized
this solution for a subset of multivariate HMDPs where all piecewise
functions had to have rectilinear piece boundaries (i.e., general
linear inequalities like $x + y > 0$ where disallowed) and actions
were discrete.  Li and Littman~\cite{li05} extended Feng {\it et al}'s
model to the case of bounded approximation using rectilinear piecewise
\emph{constant} functions that %by definition
 could not produce
the low-error linear approximations in Figures~\ref{fig:stepfunfig}(a,b)
or~\ref{fig:steplining}.  In addition,  all of these methods
could only provide (approximately) optimal solutions for a rectilinear
subset of \emph{discrete} action HMDPs in comparison to our
more general setting of \emph{continuous} action HMDPs with 
linear piecewise dynamics and rewards building on the work of Zamani
{\it et al}~\cite{zamani12}.  
%Hence our solutions are targeted at more
%general value function representations, namely linear XADDs, for which
%approximation has not been previously attempted.

An alternative bounded error HMDP solution is the phase-type
approximation of Marecki {\it et al}~\cite{phase07} which can
arbitrarily approximate 1D continuous MDP solutions but which does not
extend to multivariate settings or continuous actions.
In an approximate linear programming approach using basis functions, 
Kveton {\it et al}~\cite{kveton06,kveton06aaai} explore bounded
approximations and learnable basis functions for HMDPs but cannot provide 
\emph{a priori} guarantees on the maximum allowed error in a solution
as we can in our BASDP framework.  Munos and Moore~\cite{munos02} take
a variable resolution discretization approach to refining value
functions and policies, but these methods are based on rectilinear
partitioned kd-trees which can consume
prohibitive amounts of space to approximate the simple oblique
piecewise linear function of Figure~\ref{fig:symbex}, 
represented exactly as a four node XADD.

In an orthogonal direction to the work above, Meuleau {\it et
al}~\cite{hao09} investigate a search-based dynamic programming
solution to HMDPs that is restricted to optimality over a subset of
initial states.  We note that this approach admits \emph{any} dynamic
programming backup and value representation and hence can be combined with
BASDP and XADDs as proposed here --- an interesting avenue for future
work.

